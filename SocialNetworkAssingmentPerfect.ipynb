{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "# Variable N (N cuts of timestamp)\n",
    "N = 3\n",
    "\n",
    "# Read data and convert it to dataframe\n",
    "data = pd.read_csv(\"E:\\MOCCA\\Downloads\\SocialNetwork\\SocialMiniMini5k.csv\", sep=' ')\n",
    "data\n",
    "graph_data = pd.DataFrame(data)\n",
    "timestamps = graph_data['timestamp']\n",
    "timestamps = pd.DataFrame(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp    1217567877\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st question\n",
    "# Find tmin\n",
    "tmin = timestamps.min()\n",
    "tmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp    1219012354\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find tmax\n",
    "tmax = timestamps.max()\n",
    "tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find intervals\n",
    "intervals = np.array_split(data, N)\n",
    "intervals\n",
    "intervalsList = []\n",
    "for i in intervals:\n",
    "    intervalsList.append('(' + str(i['timestamp'].iloc[0]) + ',' + str(i['timestamp'].iloc[-1]) + ')')\n",
    "\n",
    "# intervalsList\n",
    "# intervals[0]\n",
    "# TODO FOR all dicts for intervals\n",
    "# intervalsDict = intervals[0].to_dict()\n",
    "# # intervalsDict['target_id']\n",
    "# intervals[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<networkx.classes.digraph.DiGraph at 0x278db6bc7f0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x278da74a588>,\n",
       " <networkx.classes.digraph.DiGraph at 0x278da74a390>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs = []\n",
    "for i in range(0, N):\n",
    "    directed_graph = nx.DiGraph()\n",
    "    edges = [ (edge[0], edge[1], {'timestamp': edge[2] }) for edge in intervals[i].values ]\n",
    "    directed_graph.add_edges_from(edges)\n",
    "    graphs.append(directed_graph)\n",
    "graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4th question\n",
    "# 1) DEGREE CENTRALITY\n",
    "degree_centrality = {}\n",
    "for i in range(0, N):\n",
    "    degree_centrality[i] = nx.degree_centrality(graphs[i])\n",
    "\n",
    "# degree_centrality[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2) IN-DEGREE CENTRALITY\n",
    "in_degree_centrality = {}\n",
    "for i in range(0, N):\n",
    "    in_degree_centrality[i] = nx.in_degree_centrality(graphs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3) OUT-DEGREE CENTRALITY\n",
    "out_degree_centrality = {}\n",
    "for i in range(0, N):\n",
    "    out_degree_centrality[i] = nx.out_degree_centrality(graphs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4) CLOSENESS CENTRALITY\n",
    "closeness_centrality = {}\n",
    "for i in range(0, N):\n",
    "    closeness_centrality[i] = nx.closeness_centrality(graphs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5) Betweenness Centrality\n",
    "betweenness_degree_centrality = {}\n",
    "for i in range(0, N):\n",
    "    betweenness_degree_centrality[i] = nx.betweenness_centrality(graphs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6) Eigenvector Centrality\n",
    "eigenvector_degree_centrality = {}\n",
    "for i in range(0, N):\n",
    "    eigenvector_degree_centrality[i] = nx.eigenvector_centrality(graphs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7) Katz Centrality\n",
    "\n",
    "katz_degree_centrality = {}\n",
    "for i in range(0, N):\n",
    "    katz_degree_centrality[i] = nx.katz_centrality_numpy(graphs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5) Question\n",
    "# graph vars contains the neighbors\n",
    "# common_nodes contains the intersection of graphs\n",
    "# graph_pairs is a list of dictionaries of the common nodes containing the neighbors of each subgraph\n",
    "# .neighbors returns only succesors nodes not predeccesors\n",
    "# We checked the source nodes, if they got neighbors and are succesors.\n",
    "\n",
    "# In general, we found the neighbors for the first subgraph and the neighbors for the second subgraph only for source nodes.\n",
    "\n",
    "graph_pairs = []\n",
    "for i in range(0, N - 1):\n",
    "    graph1 = [x for x in graphs[i].nodes if any(graphs[i].neighbors(x))]\n",
    "    graph2 = [x for x in graphs[i+1].nodes if any(graphs[i+1].neighbors(x))]\n",
    "    common_nodes = set(graph1).intersection(graph2)\n",
    "    graph_pairs.append( dict( (source_id, [list(graphs[i].edges(source_id)), list(graphs[i+1].edges(source_id)) ]) for source_id in common_nodes) )\n",
    "# graph_pairs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[512,\n",
       " 395,\n",
       " 1,\n",
       " 233,\n",
       " 67,\n",
       " 5,\n",
       " 32,\n",
       " 91,\n",
       " 116,\n",
       " 230,\n",
       " 637,\n",
       " 518,\n",
       " 25,\n",
       " 58,\n",
       " 362,\n",
       " 519,\n",
       " 35,\n",
       " 328,\n",
       " 274,\n",
       " 521,\n",
       " 308,\n",
       " 121,\n",
       " 350,\n",
       " 296,\n",
       " 111,\n",
       " 522,\n",
       " 590,\n",
       " 358,\n",
       " 92,\n",
       " 13,\n",
       " 23,\n",
       " 11,\n",
       " 85,\n",
       " 236,\n",
       " 525,\n",
       " 1384652,\n",
       " 527,\n",
       " 572,\n",
       " 235,\n",
       " 55,\n",
       " 539,\n",
       " 17,\n",
       " 72,\n",
       " 48,\n",
       " 83,\n",
       " 49,\n",
       " 30,\n",
       " 2089740,\n",
       " 383,\n",
       " 394,\n",
       " 136,\n",
       " 571,\n",
       " 575,\n",
       " 556,\n",
       " 34,\n",
       " 45,\n",
       " 1525924,\n",
       " 20,\n",
       " 357,\n",
       " 342,\n",
       " 547,\n",
       " 533,\n",
       " 484,\n",
       " 76,\n",
       " 560,\n",
       " 369,\n",
       " 534,\n",
       " 536,\n",
       " 234,\n",
       " 404,\n",
       " 61,\n",
       " 192,\n",
       " 117,\n",
       " 307,\n",
       " 406,\n",
       " 396,\n",
       " 682,\n",
       " 26,\n",
       " 71,\n",
       " 242,\n",
       " 95,\n",
       " 437,\n",
       " 551,\n",
       " 106,\n",
       " 673,\n",
       " 541,\n",
       " 443,\n",
       " 567,\n",
       " 543,\n",
       " 33,\n",
       " 39,\n",
       " 172,\n",
       " 277,\n",
       " 195,\n",
       " 227,\n",
       " 105,\n",
       " 115,\n",
       " 93,\n",
       " 203,\n",
       " 314,\n",
       " 380,\n",
       " 432,\n",
       " 415,\n",
       " 514,\n",
       " 46,\n",
       " 384,\n",
       " 312,\n",
       " 149,\n",
       " 517,\n",
       " 44,\n",
       " 549,\n",
       " 205,\n",
       " 423,\n",
       " 122,\n",
       " 36,\n",
       " 37,\n",
       " 40,\n",
       " 381,\n",
       " 550,\n",
       " 59,\n",
       " 146637,\n",
       " 340,\n",
       " 50,\n",
       " 264,\n",
       " 402,\n",
       " 42,\n",
       " 206,\n",
       " 231,\n",
       " 9,\n",
       " 194,\n",
       " 2,\n",
       " 281,\n",
       " 292,\n",
       " 193,\n",
       " 109,\n",
       " 245,\n",
       " 100,\n",
       " 434,\n",
       " 147,\n",
       " 81,\n",
       " 318,\n",
       " 51,\n",
       " 191,\n",
       " 214,\n",
       " 260,\n",
       " 503,\n",
       " 202,\n",
       " 390,\n",
       " 563,\n",
       " 626,\n",
       " 8,\n",
       " 78,\n",
       " 254,\n",
       " 483,\n",
       " 486,\n",
       " 253,\n",
       " 60,\n",
       " 186,\n",
       " 123,\n",
       " 331,\n",
       " 574,\n",
       " 63,\n",
       " 271,\n",
       " 580,\n",
       " 62,\n",
       " 269,\n",
       " 204,\n",
       " 75,\n",
       " 429,\n",
       " 77,\n",
       " 243,\n",
       " 349,\n",
       " 163,\n",
       " 453,\n",
       " 588,\n",
       " 309844,\n",
       " 634,\n",
       " 598,\n",
       " 364,\n",
       " 134,\n",
       " 143,\n",
       " 131,\n",
       " 200,\n",
       " 246,\n",
       " 120,\n",
       " 373,\n",
       " 303,\n",
       " 435,\n",
       " 327,\n",
       " 87,\n",
       " 479,\n",
       " 605,\n",
       " 267,\n",
       " 238,\n",
       " 608,\n",
       " 332,\n",
       " 96,\n",
       " 666,\n",
       " 611,\n",
       " 613,\n",
       " 431,\n",
       " 615,\n",
       " 103,\n",
       " 617,\n",
       " 501,\n",
       " 618,\n",
       " 145,\n",
       " 557,\n",
       " 323,\n",
       " 619,\n",
       " 199,\n",
       " 157,\n",
       " 2090742,\n",
       " 422,\n",
       " 257,\n",
       " 488,\n",
       " 670,\n",
       " 636,\n",
       " 645,\n",
       " 137,\n",
       " 657,\n",
       " 660,\n",
       " 150,\n",
       " 154,\n",
       " 79,\n",
       " 3394,\n",
       " 287,\n",
       " 676,\n",
       " 164,\n",
       " 219,\n",
       " 680,\n",
       " 170,\n",
       " 173,\n",
       " 188,\n",
       " 280,\n",
       " 298,\n",
       " 304,\n",
       " 258,\n",
       " 198,\n",
       " 372,\n",
       " 101,\n",
       " 232,\n",
       " 371,\n",
       " 454,\n",
       " 162,\n",
       " 207,\n",
       " 216,\n",
       " 302,\n",
       " 224,\n",
       " 225,\n",
       " 377,\n",
       " 326,\n",
       " 446,\n",
       " 447,\n",
       " 391,\n",
       " 576,\n",
       " 244,\n",
       " 104,\n",
       " 370,\n",
       " 259,\n",
       " 266,\n",
       " 493,\n",
       " 609,\n",
       " 439,\n",
       " 268,\n",
       " 275,\n",
       " 379,\n",
       " 279,\n",
       " 283,\n",
       " 1199387,\n",
       " 285,\n",
       " 305,\n",
       " 417,\n",
       " 316,\n",
       " 311,\n",
       " 152,\n",
       " 322,\n",
       " 341,\n",
       " 475,\n",
       " 462,\n",
       " 291,\n",
       " 146270,\n",
       " 184,\n",
       " 476,\n",
       " 22,\n",
       " 86,\n",
       " 398,\n",
       " 861,\n",
       " 288,\n",
       " 414,\n",
       " 419,\n",
       " 392,\n",
       " 20207,\n",
       " 430,\n",
       " 681,\n",
       " 457,\n",
       " 324,\n",
       " 155,\n",
       " 459,\n",
       " 482,\n",
       " 489,\n",
       " 507]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) Question\n",
    "# Graph creation\n",
    "\n",
    "# sub_graphs is a list that will contain the sub graphs\n",
    "sub_graphs = []\n",
    "# we iterate from 0 to N-1 and we create a Directed Graph every iteration\n",
    "for i in range(0, N-1):\n",
    "    sub_directed_graph = nx.DiGraph()\n",
    "    # we iterate all the keys in tha graph_pairs dictionary from the last question\n",
    "    for j in graph_pairs[i]:\n",
    "        # var edges contains the first list of edges(edges that existed in the previous time period)\n",
    "        edges = graph_pairs[i][j][0]\n",
    "        # we add the edges in the sub_directed_graph\n",
    "        sub_directed_graph.add_edges_from(edges)\n",
    "    # we append the final sub_directed_graph in the sub_graphs list\n",
    "    sub_graphs.append(sub_directed_graph)\n",
    "list(sub_graphs[0].nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.i) Length of Shortest Path\n",
    "length_shortest_path = []\n",
    "for i in range(0, N-1): \n",
    "    shortest_path_iterator = dict(nx.all_pairs_shortest_path_length(sub_graphs[i]))\n",
    "    length_shortest_path.append(shortest_path_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6.ii) Common Neighbors\n",
    "sub_common_neighbors_list = []\n",
    "for i in range(0, N-1):\n",
    "    sub_common_neighbors = {u:  {v: len(set(sub_graphs[i].successors(u)).intersection(set(sub_graphs[i].successors(v)))) for v in list(sub_graphs[i].nodes) } for u in list(sub_graphs[i].nodes) }\n",
    "    sub_common_neighbors_list.append(sub_common_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<networkx.classes.graph.Graph at 0x278da8a9b38>,\n",
       " <networkx.classes.graph.Graph at 0x278da8a9b00>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Digraph to undirected\n",
    "sub_graphs_undirected = []\n",
    "for i in range(0, N-1):\n",
    "    sub_graphs_undirected_graph = nx.Graph()\n",
    "    sub_graphs_undirected_graph = sub_graphs[i].to_undirected()\n",
    "    sub_graphs_undirected.append(sub_graphs_undirected_graph)\n",
    "sub_graphs_undirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6.iii) Jaccard coefficient\n",
    "jaccard_list = []\n",
    "for i in range(0, N-1):\n",
    "    jaccard_iterator = nx.jaccard_coefficient(sub_graphs_undirected[i])\n",
    "    dummylist = []\n",
    "    for j in jaccard_iterator:\n",
    "        x, y, z = j\n",
    "        dummylist.append((x, y ,z))\n",
    "    jaccard_dictionary = { x[0]: { y[1]: y[2] for y in dummylist if y[0] == x[0] } for x in dummylist }\n",
    "    jaccard_list.append(jaccard_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6.iv) Adamic/Adar\n",
    "    \n",
    "adamic_list = []\n",
    "for i in range(0, N-1):\n",
    "    adamic_iterator = nx.adamic_adar_index(sub_graphs_undirected[i])\n",
    "    dummylist = []\n",
    "    for j in adamic_iterator:\n",
    "        x, y, z = j\n",
    "        dummylist.append((x, y ,z))\n",
    "    adamic_dictionary = { x[0]: { y[1]: y[2] for y in dummylist if y[0] == x[0] } for x in dummylist }\n",
    "    adamic_list.append(adamic_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6.v) Preferential Attachment\n",
    "preferential_attachment_list = []\n",
    "for i in range(0, N-1):\n",
    "    preferential_attachment_iterator = nx.preferential_attachment(sub_graphs_undirected[i])\n",
    "    dummylist = []\n",
    "    for j in preferential_attachment_iterator:\n",
    "        x, y, z = j\n",
    "        dummylist.append((x, y ,z))\n",
    "    preferential_attachment_dictionary = { x[0]: { y[1]: y[2] for y in dummylist if y[0] == x[0] } for x in dummylist }\n",
    "    preferential_attachment_list.append(preferential_attachment_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get percentages of top similarity measures from user\n",
    "import operator\n",
    "\n",
    "pGD = float(5)\n",
    "pCN = float(5)\n",
    "pJC = float(5)\n",
    "pA = float(5)\n",
    "pPA = float(5)\n",
    "    \n",
    "# List of dictionaries with similarity measures for every subgraph\n",
    "similarity_measures_dicts = { 'pGD': length_shortest_path, 'pCN':\n",
    "    sub_common_neighbors_list , 'pJC': jaccard_list, 'pA': adamic_list ,'pPA': preferential_attachment_list }\n",
    "# Percentage of top similarity measures\n",
    "similarity_measures_top = { 'pGD': pGD, 'pCN': pCN , 'pJC': pJC, 'pA': pA ,'pPA': pPA }\n",
    "# Dictionary with final results for each measure\n",
    "similarity_measures_final_results = { }\n",
    "# Each iteration add final result of similarity measure combining results\n",
    "# of pairs of graphs.\n",
    "for measure, top in similarity_measures_top.items():\n",
    "    top_int = int(sub_graphs[i].size()*top)\n",
    "    pair_graph_results = []\n",
    "    # Calculate success rate for each pair of graphs\n",
    "    for i in range(0, N-1):\n",
    "        max_dict = {}\n",
    "        # Find max similarity measure for each key\n",
    "        for key, value in similarity_measures_dicts[measure][i].items():\n",
    "            max_key = max(value.items(), key=operator.itemgetter(1))[0]\n",
    "            max_dict[(key,max_key)] = value[max_key]\n",
    "        # Get top% edges based on similarity measures\n",
    "        max_dict = dict(sorted(max_dict.items(), key=operator.itemgetter(1), reverse=True)[:top_int])\n",
    "        # print(max_dict)\n",
    "        # print(\"\\n\")\n",
    "        successes = 0\n",
    "#             print([ edges[1][i] for edges in graph_pairs[i].values() for i, val in enumerate(edges[1]) ])\n",
    "#             print(\"\\n\")\n",
    "#             print(max_dict.keys())\n",
    "#             print(\"\\n\")\n",
    "        for edge in max_dict.keys():\n",
    "            if edge in [ edges[1][i] for edges in graph_pairs[i].values() for i, val in enumerate(edges[1]) ]:\n",
    "                successes += 1\n",
    "        pair_graph_results.append(successes / top_int)\n",
    "    similarity_measures_final_results[measure] = pair_graph_results\n",
    "#     print(similarity_measures_final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pA': [0.0007366482504604051, 0.00018416206261510129],\n",
       " 'pCN': [0.00570902394106814, 0.0055248618784530384],\n",
       " 'pGD': [0.00036832412523020257, 0.0005524861878453039],\n",
       " 'pJC': [0.00018416206261510129, 0.00018416206261510129],\n",
       " 'pPA': [0.001289134438305709, 0.0009208103130755065]}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_measures_final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
